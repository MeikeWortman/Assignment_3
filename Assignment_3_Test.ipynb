{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e02534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Iterable, List, Dict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7482bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# cd \"folderpath\"\n",
    "# git clone <link>\n",
    "\n",
    "# git add .\n",
    "# git commit -m \"commit message\"\n",
    "# git push "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d87b0",
   "metadata": {},
   "source": [
    "# Selection Strategy for adoption: imitate and logistic #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e82506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We will start with analysing the system using imitate first, we will test our policy suggestion in logit as well to see if it still\n",
    "    performs well under more realsitic, noisy behaviour \"\"\"\n",
    "\n",
    "def choose_strategy_imitate(agent, neighbors):\n",
    "    \"\"\"Choose strategy of the highest-payoff neighbour (including self).\"\"\"\n",
    "    candidates = neighbors + [agent]\n",
    "    best = max(candidates, key=lambda a: a.payoff)\n",
    "    return best.strategy\n",
    "\n",
    "\n",
    "def choose_strategy_logit(agent, neighbors, a_I, b, tau):\n",
    "    \"\"\"Choose strategy using logit / softmax choice.\n",
    "\n",
    "    Parameters\n",
    "    - agent: the agent choosing a strategy\n",
    "    - neighbors: list of neighbour agents\n",
    "    - a_I: effective coordination payoff given current infrastructure\n",
    "    - b: defection payoff\n",
    "    - tau: temperature parameter for softmax\n",
    "    \"\"\"\n",
    "    # compute expected payoffs for C and D \n",
    "    \"\"\" Still have to do determine C and D pi! \"\"\"\n",
    "    pi_C = 0.0\n",
    "    pi_D = 0.0\n",
    "    for other in neighbors:\n",
    "        s_j = other.strategy\n",
    "        if s_j == \"C\":\n",
    "            pi_C += a_I\n",
    "            pi_D += b\n",
    "        else:\n",
    "            pi_C += 0.0\n",
    "            pi_D += b\n",
    "\n",
    "    # softmax choice\n",
    "    denom = np.exp(pi_C / tau) + np.exp(pi_D / tau)\n",
    "    P_C = np.exp(pi_C / tau) / denom if denom > 0 else 0.5\n",
    "    return \"C\" if random.random() < P_C else \"D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d5e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
