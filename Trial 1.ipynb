{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Callable, Iterable, List, Dict, Optional, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1428f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We will start with analysing the system using imitate first, we will test our policy suggestion in logit as well to see if it still\n",
    "    performs well under more realsitic, noisy behaviour \"\"\"\n",
    "\n",
    "def choose_strategy_imitate(agent, neighbors):\n",
    "    \"\"\"Choose strategy of the highest-payoff neighbour (including self).\"\"\"\n",
    "    candidates = neighbors + [agent]\n",
    "    best = max(candidates, key=lambda a: a.payoff)\n",
    "    return best.strategy\n",
    "\n",
    "def choose_strategy_logit(agent, neighbors, a_I, b, tau):\n",
    "    \"\"\"Choose strategy using logit / softmax choice.\n",
    "\n",
    "    Parameters\n",
    "    - agent: the agent choosing a strategy\n",
    "    - neighbors: list of neighbour agents\n",
    "    - a_I: effective coordination payoff given current infrastructure\n",
    "    - b: defection payoff\n",
    "    - tau: temperature parameter for softmax\n",
    "    \"\"\"\n",
    "    # compute expected payoffs for C and D \n",
    "    \"\"\" Still have to do determine C and D pi! \"\"\"\n",
    "    pi_C = 0.0\n",
    "    pi_D = 0.0\n",
    "    for other in neighbors:\n",
    "        s_j = other.strategy\n",
    "        if s_j == \"C\":\n",
    "            pi_C += a_I\n",
    "            pi_D += b\n",
    "        else:\n",
    "            pi_C += 0.0\n",
    "            pi_D += b\n",
    "\n",
    "    # softmax choice\n",
    "    denom = np.exp(pi_C / tau) + np.exp(pi_D / tau)\n",
    "    P_C = np.exp(pi_C / tau) / denom if denom > 0 else 0.5\n",
    "    return \"C\" if random.random() < P_C else \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00db3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_subsidy_factory(start: int, end: int, delta_a0: float = 0.3, delta_beta_I: float = 0.0) -> Callable:\n",
    "    \"\"\"Create a policy that temporarily boosts coordination payoffs.\n",
    "\n",
    "    Raises `a0` and/or `beta_I` during `[start, end)` and reverts after.\n",
    "    Returns a closure `policy(model, step)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def policy(model, step):\n",
    "        if not hasattr(policy, \"base_a0\"):\n",
    "            policy.base_a0 = model.a0\n",
    "        if not hasattr(policy, \"base_beta_I\"):\n",
    "            policy.base_beta_I = model.beta_I\n",
    "\n",
    "        if start <= step < end:\n",
    "            model.a0 = policy.base_a0 + delta_a0\n",
    "            model.beta_I = policy.base_beta_I + delta_beta_I\n",
    "        else:\n",
    "            model.a0 = policy.base_a0\n",
    "            model.beta_I = policy.base_beta_I\n",
    "\n",
    "    return policy\n",
    "\n",
    "def policy_infrastructure_boost_factory(start: int, boost: float = 0.2, once: bool = True) -> Callable:\n",
    "    \"\"\"Create a policy that injects infrastructure at a specific step.\"\"\"\n",
    "\n",
    "    def policy(model, step):\n",
    "        if step < start:\n",
    "            return\n",
    "        if once:\n",
    "            if not hasattr(policy, \"done\"):\n",
    "                model.infrastructure = float(np.clip(model.infrastructure + boost, 0.0, 1.0))\n",
    "                policy.done = True\n",
    "        else:\n",
    "            model.infrastructure = float(np.clip(model.infrastructure + boost, 0.0, 1.0))\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d58bf301",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Agent class\n",
    "#\n",
    "# The EVAgent class implements the single agent at a graph node.\n",
    "#\n",
    "# Attributes\n",
    "# - strategy: \"C\" (adopt EV) or \"D\" (defect / ICE)\n",
    "# - payoff: accumulated payoff from interactions with neighbours\n",
    "# - next_strategy: strategy chosen for the next time step\n",
    "####################################\n",
    "class EVAgent(Agent):\n",
    "    \"\"\"Single agent at a graph node.\n",
    "\n",
    "    Attributes\n",
    "    - strategy: \"C\" (adopt EV) or \"D\" (defect / ICE)\n",
    "    - payoff: accumulated payoff from interactions with neighbours\n",
    "    - next_strategy: strategy chosen for the next time step\n",
    "    \"\"\"\n",
    "# Initial conditions, runs when a new agent is created. Each agent starts with: a strategy (C/D), zero payoff and a next strategy based on neighbours\n",
    "    def __init__(self, unique_id, model, init_strategy=\"D\"):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.strategy = init_strategy\n",
    "        self.payoff = 0.0\n",
    "        self.next_strategy = init_strategy\n",
    "# Calculate payoff of current strategy \n",
    "    def step(self):\n",
    "        \"\"\"Compute payoff from interactions with neighbours.\n",
    "\n",
    "        Stag Hunt payoff rules:\n",
    "        - C vs C: `a_I` (coordination enhanced by infrastructure)\n",
    "        - C vs D: 0\n",
    "        - D vs C: `b`\n",
    "        - D vs D: `b`\n",
    "        \"\"\"\n",
    "        I = self.model.infrastructure           # Current infrastructure level\n",
    "        a0 = self.model.a0                      # Base coordination payoff for EV adoption\n",
    "        beta_I = self.model.beta_I              # Strength of infrastructure feedback\n",
    "        b = self.model.b                        # payoff from sticking with ICE\n",
    "        a_I = a0 + beta_I * I                   # effective payoff for EVâ€“EV interaction\n",
    "\n",
    "        neighbor_agents = []\n",
    "        for nbr in self.model.G.neighbors(self.pos):\n",
    "            neighbor_agents.extend(self.model.grid.get_cell_list_contents([nbr]))\n",
    "        if not neighbor_agents:\n",
    "            self.payoff = 0.0\n",
    "            return\n",
    "\n",
    "        payoff = 0.0\n",
    "        for other in neighbor_agents:\n",
    "            s_i = self.strategy\n",
    "            s_j = other.strategy\n",
    "            if s_i == \"C\" and s_j == \"C\":\n",
    "                payoff += a_I\n",
    "            elif s_i == \"C\" and s_j == \"D\":\n",
    "                payoff += 0.0\n",
    "            elif s_i == \"D\" and s_j == \"C\":\n",
    "                payoff += b\n",
    "            else:\n",
    "                payoff += b\n",
    "        self.payoff = payoff\n",
    "\n",
    "    ####################################\n",
    "    # Advance method\n",
    "    #\n",
    "    # The advance method updates the agent's strategy based on the selected rule.\n",
    "    #\n",
    "    # Parameters\n",
    "    # - strategy_choice_func: the strategy selection function to use (\"imitate\" or \"logit\")\n",
    "    ####################################\n",
    "\n",
    "    def advance(self, strategy_choice_func=\"imitate\"):\n",
    "        \"\"\"Update next_strategy using the selected rule.\n",
    "\n",
    "        If called without an explicit rule, read `self.model.strategy_choice_func`.\n",
    "        Commit `self.strategy = self.next_strategy` for synchronous updates.\n",
    "        \"\"\"\n",
    "        func = strategy_choice_func if strategy_choice_func is not None else getattr(self.model, \"strategy_choice_func\", \"imitate\")\n",
    "\n",
    "        neighbor_agents = []\n",
    "        for nbr in self.model.G.neighbors(self.pos):\n",
    "            neighbor_agents.extend(self.model.grid.get_cell_list_contents([nbr]))\n",
    "\n",
    "        if func == \"imitate\":\n",
    "            self.next_strategy = choose_strategy_imitate(self, neighbor_agents)\n",
    "        elif func == \"logit\":\n",
    "            a_I = self.model.a0 + self.model.beta_I * self.model.infrastructure\n",
    "            self.next_strategy = choose_strategy_logit(self, neighbor_agents, a_I, self.model.b, getattr(self.model, \"tau\", 1.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy choice function: {func}\")\n",
    "\n",
    "        self.strategy = self.next_strategy\n",
    "\n",
    "class EVStagHuntModel(Model):\n",
    "    \"\"\"Mesa model for EV Stag Hunt on a network.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        initial_ev=10, # - initial_ev: number of initial EV nodes\n",
    "        a0=2.0, # - a0: base payoff for EV adoption\n",
    "        beta_I=3.0, # - beta_I: payoff enhancement factor for EV adoption\n",
    "        b=1.0, # - b: payoff for ICE defection\n",
    "        g_I=0.1, # - g_I: infrastructure growth rate\n",
    "        I0=0.05, # - I0: initial infrastructure level\n",
    "        seed=42,\n",
    "        network_type=\"random\",\n",
    "        n_nodes=100,\n",
    "        p=0.05,\n",
    "        m=2,\n",
    "        k=30,\n",
    "        collect=True,\n",
    "        strategy_choice_func: str = \"imitate\",\n",
    "        tau: float = 1.0,\n",
    "    ):\n",
    "        super().__init__(seed=seed)\n",
    "\n",
    "        # Build graph\n",
    "        if network_type == \"BA\":\n",
    "            G = nx.barabasi_albert_graph(n_nodes, 15, seed=seed)\n",
    "\n",
    "        elif network_type == \"ER\":\n",
    "            G = nx.erdos_renyi_graph(n_nodes, p, seed=seed)\n",
    "\n",
    "        elif network_type == \"WS\":\n",
    "            k = k if k % 2 == 0 else k + 1  # Ensure even for WS\n",
    "            G = nx.watts_strogatz_graph(n=n_nodes, k=30, p=0.3, seed=seed)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown network_type: {network_type}\")\n",
    "\n",
    "        self.G = G\n",
    "        self.grid = NetworkGrid(G)\n",
    "        self.schedule = SimultaneousActivation(self)\n",
    "\n",
    "        # parameters\n",
    "        self.a0 = a0\n",
    "        self.beta_I = beta_I\n",
    "        self.b = b\n",
    "        self.g_I = g_I\n",
    "        self.infrastructure = I0\n",
    "        self.step_count = 0\n",
    "        self.strategy_choice_func = strategy_choice_func\n",
    "        self.tau = tau\n",
    "\n",
    "        # initialize node attribute for agent reference\n",
    "        for n in self.G.nodes:\n",
    "            self.G.nodes[n][\"agent\"] = []\n",
    "\n",
    "        # choose initial EV nodes\n",
    "        total_nodes = self.G.number_of_nodes()\n",
    "        k_ev = max(0, min(initial_ev, total_nodes))\n",
    "        ev_nodes = set(self.random.sample(list(self.G.nodes), k_ev))\n",
    "\n",
    "        # create one agent per node\n",
    "        uid = 0\n",
    "        for node in self.G.nodes:\n",
    "            init_strategy = \"C\" if node in ev_nodes else \"D\"\n",
    "            agent = EVAgent(uid, self, init_strategy)\n",
    "            uid += 1\n",
    "            self.schedule.add(agent)\n",
    "            self.grid.place_agent(agent, node)\n",
    "\n",
    "        self.datacollector = None\n",
    "        if collect:\n",
    "            self.datacollector = DataCollector(\n",
    "                model_reporters={\n",
    "                    \"X\": self.get_adoption_fraction,\n",
    "                    \"I\": lambda m: m.infrastructure,\n",
    "                },\n",
    "                agent_reporters={\"strategy\": \"strategy\", \"payoff\": \"payoff\"},\n",
    "            )\n",
    "\n",
    "    def get_adoption_fraction(self):\n",
    "        agents = self.schedule.agents\n",
    "        if not agents:\n",
    "            return 0.0\n",
    "        return sum(1 for a in agents if a.strategy == \"C\") / len(agents)\n",
    "\n",
    "    # ####################\n",
    "    # Model step function\n",
    "    #\n",
    "    # The step function advances the model by one time step.\n",
    "    # It first advances all agents, then computes the adoption fraction and infrastructure level.\n",
    "    # The infrastructure level is updated based on the adoption fraction and the infrastructure growth rate.\n",
    "    # The updated infrastructure level is clipped to the interval [0, 1].\n",
    "    # Finally, if data collection is enabled, the model and agent data are collected.\n",
    "    #######################\n",
    "    def step(self): \n",
    "        self.schedule.step() # advance all agents\n",
    "        X = self.get_adoption_fraction() # compute adoption fraction after all agents have advanced\n",
    "        I = self.infrastructure # infrastructure level before this step\n",
    "        dI = self.g_I * (X - I) # infrastructure growth rate, impacted by adoption fraction\n",
    "        self.infrastructure = float(min(1.0, max(0.0, I + dI))) # clip infrastructure level to [0, 1]\n",
    "        if self.datacollector is not None:\n",
    "            self.datacollector.collect(self) # collect data at the end of each step\n",
    "        self.step_count += 1 # increment step count after data collection\n",
    "\n",
    "#########################\n",
    "#\n",
    "# Set initial adopters\n",
    "# \n",
    "# Parameters\n",
    "# - model: the EVStagHuntModel instance\n",
    "# - X0_frac: fraction of agents to initially choose EV adoption\n",
    "# - method: method to choose initial adopters (\"random\" or \"degree\")\n",
    "# - seed: random seed for reproducibility\n",
    "# - high: whether to choose high or low degree nodes for \"degree\" method\n",
    "###########################\n",
    "def set_initial_adopters(model, X0_frac, method=\"random\", seed=None, high=True):\n",
    "    \"\"\"Set a fraction of agents to EV adopters using different heuristics.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    agents = model.schedule.agents\n",
    "    n = len(agents)\n",
    "    k = int(round(X0_frac * n))\n",
    "\n",
    "    for a in agents:\n",
    "        a.strategy = \"D\"\n",
    "\n",
    "    if k <= 0:\n",
    "        return\n",
    "\n",
    "    if method == \"random\":\n",
    "        idx = rng.choice(n, size=k, replace=False)\n",
    "        for i in idx:\n",
    "            agents[i].strategy = \"C\"\n",
    "        return\n",
    "\n",
    "    if method == \"degree\":\n",
    "        deg = dict(model.G.degree())\n",
    "        ordered_nodes = sorted(deg.keys(), key=lambda u: deg[u], reverse=high)\n",
    "        chosen = set(ordered_nodes[:k])\n",
    "        for a in agents:\n",
    "            if a.unique_id in chosen:\n",
    "                a.strategy = \"C\"\n",
    "        return\n",
    "\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Ratio sweep helpers (computation-only)\n",
    "# -----------------------------\n",
    "#########################\n",
    "#\n",
    "# Run a single network trial\n",
    "# \n",
    "# Parameters\n",
    "# - X0_frac: fraction of agents to initially choose EV adoption\n",
    "# - ratio: payoff ratio between EV and DC agents (a0 = ratio*b - beta_I*I0)\n",
    "# - I0: initial infrastructure level\n",
    "# - beta_I: cost of EV adoption relative to DC (beta_I*I0)\n",
    "# - b: payoff of EV (b)\n",
    "# - g_I: infrastructure growth rate (g_I)\n",
    "# - T: number of time steps to run\n",
    "# - network_type: type of network to generate (\"random\" or \"BA\")\n",
    "# - n_nodes: number of nodes in the network\n",
    "# - p: probability of edge creation in random network\n",
    "# - m: number of edges to attach from a new node to existing nodes in BA network\n",
    "# - seed: random seed for reproducibility\n",
    "# - tol: tolerance for convergence check (default: 1e-3)\n",
    "# - patience: number of steps to wait for convergence (default: 30)\n",
    "\n",
    "def run_network_trial(\n",
    "    X0_frac: float,\n",
    "    ratio: float = 2.0,\n",
    "    *,\n",
    "    I0: float = 0.05,\n",
    "    beta_I: float = 2.0,\n",
    "    b: float = 1.0,\n",
    "    g_I: float = 0.05,\n",
    "    T: int = 200,\n",
    "    network_type: str = \"ER\",\n",
    "    n_nodes: int = 120,\n",
    "    p: float = 0.05,\n",
    "    m: int = 2,\n",
    "    k: int = 30,\n",
    "    seed: int | None = None,\n",
    "    tol: float = 1e-3,\n",
    "    patience: int = 30,\n",
    "    collect: bool = True,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    ") -> float:\n",
    "    \"\"\"Run a single realisation and return final adoption fraction.\n",
    "\n",
    "    Preserves the intended initial payoff ratio via a0 = ratio*b - beta_I*I0.\n",
    "    Includes basic stability-based early stopping.\n",
    "    \"\"\"\n",
    "    initial_ev = int(round(X0_frac * n_nodes))\n",
    "    a0 = ratio * b - beta_I * I0\n",
    "\n",
    "    model = EVStagHuntModel(\n",
    "        initial_ev=initial_ev,\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        I0=I0,\n",
    "        seed=seed,\n",
    "        network_type=network_type,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        k=k,\n",
    "        collect=collect,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    stable_steps = 0\n",
    "    prev_X = None\n",
    "    prev_I = None\n",
    "    for _ in range(T):\n",
    "        model.step()\n",
    "        X = model.get_adoption_fraction()\n",
    "        I = model.infrastructure\n",
    "        if prev_X is not None and prev_I is not None:\n",
    "            if abs(X - prev_X) < tol and abs(I - prev_I) < tol:\n",
    "                stable_steps += 1\n",
    "            else:\n",
    "                stable_steps = 0\n",
    "        prev_X, prev_I = X, I\n",
    "        if X in (0.0, 1.0) and stable_steps >= 10:\n",
    "            break\n",
    "        if stable_steps >= patience:\n",
    "            break\n",
    "\n",
    "    return model.get_adoption_fraction()\n",
    "\n",
    "#########################\n",
    "#\n",
    "# Compute final mean adoption fraction vs ratio\n",
    "# \n",
    "##########################\n",
    "def final_mean_adoption_vs_ratio(\n",
    "    X0_frac: float,\n",
    "    ratio_values: Iterable[float],\n",
    "    *,\n",
    "    I0: float = 0.05,\n",
    "    beta_I: float = 2.0,\n",
    "    b: float = 1.0,\n",
    "    g_I: float = 0.05,\n",
    "    T: int = 200,\n",
    "    network_type: str = \"random\",\n",
    "    n_nodes: int = 120,\n",
    "    p: float = 0.05,\n",
    "    m: int = 2,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute mean final adoption across a sweep of ratio values.\n",
    "\n",
    "    For each ratio, average over `batch_size` trials with jittered `I0` and seeds.\n",
    "    Returns a numpy array of means aligned with `ratio_values` order.\n",
    "    \"\"\"\n",
    "    ratios = list(ratio_values)\n",
    "    means: List[float] = []\n",
    "    for ratio in ratios:\n",
    "        finals: List[float] = []\n",
    "        for _ in range(batch_size):\n",
    "            I0_j = float(np.clip(np.random.normal(loc=I0, scale=init_noise_I), 0.0, 1.0))\n",
    "            seed_j = np.random.randint(0, 2**31 - 1)\n",
    "            x_star = run_network_trial(\n",
    "                X0_frac,\n",
    "                ratio,\n",
    "                I0=I0_j,\n",
    "                beta_I=beta_I,\n",
    "                b=b,\n",
    "                g_I=g_I,\n",
    "                T=T,\n",
    "                network_type=network_type,\n",
    "                n_nodes=n_nodes,\n",
    "                p=p,\n",
    "                m=m,\n",
    "                seed=seed_j,\n",
    "                collect=False,\n",
    "                strategy_choice_func=strategy_choice_func,\n",
    "                tau=tau,\n",
    "            )\n",
    "            finals.append(x_star)\n",
    "        means.append(float(np.mean(finals)))\n",
    "    return np.asarray(means, dtype=float)\n",
    "\n",
    "#########################\n",
    "#\n",
    "# Compute heatmap row for a fixed ratio\n",
    "# \n",
    "##########################\n",
    "def _row_for_I0_task(args: Dict) -> np.ndarray:\n",
    "    \"\"\"Top-level worker to compute one heatmap row for a fixed I0.\n",
    "\n",
    "    Returns an array of mean final adoption across provided X0_values.\n",
    "    \"\"\"\n",
    "    I0 = args[\"I0\"]\n",
    "    X0_values = args[\"X0_values\"]\n",
    "    beta_I = args[\"beta_I\"]\n",
    "    b = args[\"b\"]\n",
    "    g_I = args[\"g_I\"]\n",
    "    T = args[\"T\"]\n",
    "    network_type = args[\"network_type\"]\n",
    "    n_nodes = args[\"n_nodes\"]\n",
    "    p = args[\"p\"]\n",
    "    m = args[\"m\"]\n",
    "    batch_size = args[\"batch_size\"]\n",
    "    init_noise_I = args[\"init_noise_I\"]\n",
    "    strategy_choice_func = args[\"strategy_choice_func\"]\n",
    "    tau = args[\"tau\"]\n",
    "\n",
    "    row = np.empty(len(X0_values), dtype=float)\n",
    "    for j, X0 in enumerate(X0_values):\n",
    "        finals: List[float] = []\n",
    "        for _ in range(batch_size):\n",
    "            # Add small noise to I0 if desired\n",
    "            I0_j = float(np.clip(np.random.normal(loc=I0, scale=init_noise_I), 0.0, 1.0))\n",
    "            seed_j = np.random.randint(0, 2**31 - 1)\n",
    "            x_star = run_network_trial(\n",
    "                X0_frac=X0,\n",
    "                I0=I0_j,\n",
    "                beta_I=beta_I,\n",
    "                b=b,\n",
    "                g_I=g_I,\n",
    "                T=T,\n",
    "                network_type=network_type,\n",
    "                n_nodes=n_nodes,\n",
    "                p=p,\n",
    "                m=m,\n",
    "                seed=seed_j,\n",
    "                collect=False,\n",
    "                strategy_choice_func=strategy_choice_func,\n",
    "                tau=tau,\n",
    "            )\n",
    "            finals.append(x_star)\n",
    "        row[j] = float(np.mean(finals))\n",
    "    return row\n",
    "\n",
    "    \n",
    "#########################\n",
    "#\n",
    "# Compute heatmap matrix for phase sweep\n",
    "# \n",
    "##########################\n",
    "def phase_sweep_X0_vs_I0(\n",
    "    X0_values: Iterable[float],\n",
    "    I0_values: Iterable[float],\n",
    "    *,\n",
    "    beta_I: float = 2.0,\n",
    "    b: float = 1.0,\n",
    "    g_I: float = 0.05,\n",
    "    T: int = 250,\n",
    "    network_type: str = \"BA\",\n",
    "    n_nodes: int = 120,\n",
    "    p: float = 0.05,\n",
    "    m: int = 2,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    "    max_workers: int | None = None,\n",
    "    backend: str = \"process\",\n",
    "    seed: int = 42,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute a heatmap of mean final adoption X* over (X0, I0).\n",
    "\n",
    "    Returns an array of shape (len(I0_values), len(X0_values)), \n",
    "    rows = I0_values, columns = X0_values.\n",
    "    \"\"\"\n",
    "    X0_values = list(X0_values)\n",
    "    I0_values = list(I0_values)\n",
    "    X_final = np.zeros((len(I0_values), len(X0_values)), dtype=float)\n",
    "\n",
    "    # Prepare tasks per I0\n",
    "    tasks: List[Dict] = []\n",
    "    for I0 in I0_values:\n",
    "        tasks.append({\n",
    "            \"I0\": I0,\n",
    "            \"X0_values\": X0_values,\n",
    "            \"beta_I\": beta_I,\n",
    "            \"b\": b,\n",
    "            \"g_I\": g_I,\n",
    "            \"T\": T,\n",
    "            \"network_type\": network_type,\n",
    "            \"n_nodes\": n_nodes,\n",
    "            \"p\": p,\n",
    "            \"m\": m,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"init_noise_I\": init_noise_I,\n",
    "            \"strategy_choice_func\": strategy_choice_func,\n",
    "            \"tau\": tau,\n",
    "            \"seed\": seed,\n",
    "        })\n",
    "\n",
    "    if max_workers is None:\n",
    "        try:\n",
    "            max_workers = os.cpu_count() or 1\n",
    "        except Exception:\n",
    "            max_workers = 1\n",
    "\n",
    "    Executor = ProcessPoolExecutor if backend == \"process\" and max_workers > 1 else ThreadPoolExecutor\n",
    "    if max_workers > 1:\n",
    "        with Executor(max_workers=max_workers) as ex:\n",
    "            futures = [ex.submit(_row_for_I0_task, args) for args in tasks]\n",
    "            for i, fut in enumerate(futures):\n",
    "                row = fut.result()\n",
    "                X_final[i, :] = row\n",
    "    else:\n",
    "        for i, args in enumerate(tasks):\n",
    "            row = _row_for_I0_task(args)\n",
    "            X_final[i, :] = row\n",
    "\n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff8045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_timeseries_trial(\n",
    "    T: int = 200,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    seed: Optional[int] = 42,\n",
    "    policy: Optional[Callable] = None,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Run a single simulation and return X(t), I(t), and the model dataframe.\"\"\"\n",
    "\n",
    "    scenario = {\n",
    "        # Either provide `ratio` to pin the initial a_I/b, or explicit `a0`.\n",
    "        # Defaults here mirror the classroom-friendly values.\n",
    "        # If `ratio` is present, we compute `a0 = ratio*b - beta_I*I0`.\n",
    "        \"a0\": 2.0,\n",
    "        \"ratio\": None,\n",
    "        \"beta_I\": 3.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.1,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"ER\",\n",
    "        \"n_nodes\": 100,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "        \"k\": 30,\n",
    "        \"collect\": True,\n",
    "        \"X0_frac\": 0.0,\n",
    "        \"init_method\": \"random\",\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    # Compute a0 from ratio if provided to preserve initial payoff ratio\n",
    "    a0_for_model = scenario[\"a0\"]\n",
    "    if scenario.get(\"ratio\") is not None:\n",
    "        a0_for_model = float(scenario[\"ratio\"]) * float(scenario[\"b\"]) - float(scenario[\"beta_I\"]) * float(scenario[\"I0\"])\n",
    "\n",
    "    model = EVStagHuntModel(\n",
    "        a0=a0_for_model,\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        I0=scenario[\"I0\"],\n",
    "        seed=seed,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        k=scenario[\"k\"],\n",
    "        collect=True,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    if scenario.get(\"X0_frac\", 0.0) > 0.0:\n",
    "        set_initial_adopters(\n",
    "            model,\n",
    "            scenario[\"X0_frac\"],\n",
    "            method=scenario.get(\"init_method\", \"random\"),\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "    for t in range(T):\n",
    "        if policy is not None:\n",
    "            policy(model, t)\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe().copy()\n",
    "    return df[\"X\"].to_numpy(), df[\"I\"].to_numpy(), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1d62f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ER1_Timeseries_Tuple = run_timeseries_trial(\n",
    "    T = 100,\n",
    "    scenario_kwargs = {\n",
    "        # Either provide `ratio` to pin the initial a_I/b, or explicit `a0`.\n",
    "        # Defaults here mirror the classroom-friendly values.\n",
    "        # If `ratio` is present, we compute `a0 = ratio*b - beta_I*I0`.\n",
    "        \"ratio\": 3.0,\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 2.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"I0\": 0.1,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 300,\n",
    "        \"p\": 0.1,\n",
    "        \"m\": 2,\n",
    "        \"collect\": True,\n",
    "        \"X0_frac\": 0.45,\n",
    "        \"init_method\": \"random\",\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    policy = None,\n",
    "    strategy_choice_func= \"logit\",\n",
    "    tau= 2.0,\n",
    "    seed = 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98641143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_t, I_t, df = ER1_Timeseries_Tuple\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(X_t, label=\"X(t) â€“ Adoption\", linewidth=2)\n",
    "plt.plot(I_t, label=\"I(t) â€“ Infrastructure\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"X(t) and I(t) Timeseries\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d231084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network_trial(\n",
    "    X0_frac: float,\n",
    "    ratio: float = 2.0,\n",
    "    *,\n",
    "    I0: float = 0.05,\n",
    "    beta_I: float = 2.0,\n",
    "    b: float = 1.0,\n",
    "    g_I: float = 0.05,\n",
    "    T: int = 200,\n",
    "    network_type: str = \"ER\",\n",
    "    n_nodes: int = 120,\n",
    "    p: float = 0.05,\n",
    "    m: int = 2,\n",
    "    k: int = 30,\n",
    "    seed: int | None = None,\n",
    "    tol: float = 1e-3,\n",
    "    patience: int = 30,\n",
    "    collect: bool = True,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    ") -> float:\n",
    "    \"\"\"Run a single realisation and return final adoption fraction.\n",
    "\n",
    "    Preserves the intended initial payoff ratio via a0 = ratio*b - beta_I*I0.\n",
    "    Includes basic stability-based early stopping.\n",
    "    \"\"\"\n",
    "    initial_ev = int(round(X0_frac * n_nodes))\n",
    "    a0 = ratio * b - beta_I * I0\n",
    "\n",
    "    model = EVStagHuntModel(\n",
    "        initial_ev=initial_ev,\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        I0=I0,\n",
    "        seed=seed,\n",
    "        network_type=network_type,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        k=k,\n",
    "        collect=collect,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    stable_steps = 0\n",
    "    prev_X = None\n",
    "    prev_I = None\n",
    "    for _ in range(T):\n",
    "        model.step()\n",
    "        X = model.get_adoption_fraction()\n",
    "        I = model.infrastructure\n",
    "        if prev_X is not None and prev_I is not None:\n",
    "            if abs(X - prev_X) < tol and abs(I - prev_I) < tol:\n",
    "                stable_steps += 1\n",
    "            else:\n",
    "                stable_steps = 0\n",
    "        prev_X, prev_I = X, I\n",
    "        if X in (0.0, 1.0) and stable_steps >= 10:\n",
    "            break\n",
    "        if stable_steps >= patience:\n",
    "            break\n",
    "\n",
    "    X_traj = []  # store adoption over time\n",
    "\n",
    "    for _ in range(T):\n",
    "        model.step()\n",
    "        X = model.get_adoption_fraction()\n",
    "        if collect:\n",
    "            X_traj.append(X)\n",
    "        # stability check...\n",
    "    \n",
    "    if collect:\n",
    "        return np.array(X_traj)  # return trajectory\n",
    "    else:\n",
    "        return model.get_adoption_fraction() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e563a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _row_for_time_task(args: Dict) -> np.ndarray:\n",
    "    \"\"\"Worker to compute adoption over time for a fixed X0.\n",
    "\n",
    "    Returns an array of shape (len(time_points),) for this X0.\n",
    "    \"\"\"\n",
    "    X0 = args[\"X0\"]\n",
    "    beta_I = args[\"beta_I\"]\n",
    "    b = args[\"b\"]\n",
    "    g_I = args[\"g_I\"]\n",
    "    T = args[\"T\"]\n",
    "    network_type = args[\"network_type\"]\n",
    "    n_nodes = args[\"n_nodes\"]\n",
    "    p = args[\"p\"]\n",
    "    m = args[\"m\"]\n",
    "    batch_size = args[\"batch_size\"]\n",
    "    init_noise_I = args[\"init_noise_I\"]\n",
    "    strategy_choice_func = args[\"strategy_choice_func\"]\n",
    "    tau = args[\"tau\"]\n",
    "    time_points = args[\"time_points\"]\n",
    "\n",
    "    # We'll store the mean adoption over batches for each time point\n",
    "    X_time = np.zeros((len(time_points),), dtype=float)\n",
    "\n",
    "    for b_idx in range(batch_size):\n",
    "        seed_j = np.random.randint(0, 2**31 - 1)\n",
    "        # run_network_trial should now optionally return the full trajectory\n",
    "        X_traj = run_network_trial(\n",
    "            X0_frac=X0,\n",
    "            beta_I=beta_I,\n",
    "            b=b,\n",
    "            g_I=g_I,\n",
    "            T=T,\n",
    "            network_type=network_type,\n",
    "            n_nodes=n_nodes,\n",
    "            p=p,\n",
    "            m=m,\n",
    "            seed=seed_j,\n",
    "            collect=True,  # collect full X(t)\n",
    "            strategy_choice_func=strategy_choice_func,\n",
    "            tau=tau,\n",
    "        )\n",
    "        # X_traj assumed to be length T\n",
    "        X_time += X_traj[time_points]\n",
    "\n",
    "    # Average over batch\n",
    "    X_time /= batch_size\n",
    "    return X_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06060369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_sweep_X0_vs_time(\n",
    "    X0_values: Iterable[float],\n",
    "    time_points: Iterable[int],\n",
    "    *,\n",
    "    beta_I: float = 2.0,\n",
    "    b: float = 1.0,\n",
    "    g_I: float = 0.05,\n",
    "    T: int = 250,\n",
    "    network_type: str = \"BA\",\n",
    "    n_nodes: int = 120,\n",
    "    p: float = 0.05,\n",
    "    m: int = 2,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    "    max_workers: int | None = None,\n",
    "    backend: str = \"process\",\n",
    "    seed: int = 42,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute adoption X(t) over time for each X0 value.\n",
    "\n",
    "    Returns an array of shape (len(time_points), len(X0_values)),\n",
    "    rows = time points, columns = X0_values.\n",
    "    \"\"\"\n",
    "    X0_values = list(X0_values)\n",
    "    time_points = list(time_points)\n",
    "    X_over_time = np.zeros((len(time_points), len(X0_values)), dtype=float)\n",
    "\n",
    "    # Prepare tasks per X0\n",
    "    tasks: List[Dict] = []\n",
    "    for X0 in X0_values:\n",
    "        tasks.append({\n",
    "            \"X0\": X0,\n",
    "            \"beta_I\": beta_I,\n",
    "            \"b\": b,\n",
    "            \"g_I\": g_I,\n",
    "            \"T\": T,\n",
    "            \"network_type\": network_type,\n",
    "            \"n_nodes\": n_nodes,\n",
    "            \"p\": p,\n",
    "            \"m\": m,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"init_noise_I\": init_noise_I,\n",
    "            \"strategy_choice_func\": strategy_choice_func,\n",
    "            \"tau\": tau,\n",
    "            \"seed\": seed,\n",
    "            \"time_points\": time_points,  # new\n",
    "        })\n",
    "\n",
    "    if max_workers is None:\n",
    "        try:\n",
    "            max_workers = os.cpu_count() or 1\n",
    "        except Exception:\n",
    "            max_workers = 1\n",
    "\n",
    "    Executor = ProcessPoolExecutor if backend == \"process\" and max_workers > 1 else ThreadPoolExecutor\n",
    "\n",
    "    # Submit tasks\n",
    "    if max_workers > 1:\n",
    "        with Executor(max_workers=max_workers) as ex:\n",
    "            futures = [ex.submit(_row_for_time_task, args) for args in tasks]\n",
    "            for j, fut in enumerate(futures):\n",
    "                col = fut.result()\n",
    "                X_over_time[:, j] = col\n",
    "    else:\n",
    "        for j, args in enumerate(tasks):\n",
    "            col = _row_for_time_task(args)\n",
    "            X_over_time[:, j] = col\n",
    "\n",
    "    return X_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d8e1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BA1_X0_time_array = phase_sweep_X0_vs_time(\n",
    "    X0_values= np.linspace(0.2, 0.9, 10, dtype= float),\n",
    "    time_points= np.linspace(1, 100, 100, dtype= int),\n",
    "    beta_I = 1.5,\n",
    "    b= 2.0,\n",
    "    g_I = 0.05,\n",
    "    T= 250,\n",
    "    network_type = \"BA\",\n",
    "    n_nodes = 300,\n",
    "    p= 0.1,\n",
    "    m = 2,\n",
    "    batch_size = 16,\n",
    "    init_noise_I= 0.1,\n",
    "    strategy_choice_func= \"logit\",\n",
    "    tau= 2.0,\n",
    "    max_workers = 1,\n",
    "    backend=\"process\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d00e4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_X0_time_heatmap(df: pd.DataFrame, out_path: str | None = None):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of X(t) over (X0, time) from a DataFrame generated by phase_sweep_X0_vs_time.\n",
    "\n",
    "    df: DataFrame where\n",
    "        - df.index are time points\n",
    "        - df.columns are X0 values\n",
    "        - df.values are X(t)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract coordinates\n",
    "    time_points = df.index.values.astype(float)\n",
    "    X0_values = df.columns.values.astype(float)\n",
    "    X_over_time = df.values.astype(float)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    im = plt.imshow(\n",
    "        X_over_time,\n",
    "        origin=\"lower\",\n",
    "        extent=[X0_values.min(), X0_values.max(),\n",
    "                time_points.min(), time_points.max()],\n",
    "        aspect=\"auto\",\n",
    "        vmin=0.0,\n",
    "        vmax=1.0,\n",
    "        cmap=\"plasma\"\n",
    "    )\n",
    "\n",
    "    plt.colorbar(im, label=\"Adoption X(t)\")\n",
    "    plt.xlabel(\"X0 (initial adoption)\")\n",
    "    plt.ylabel(\"Time step\")\n",
    "    plt.title(\"Network adoption over time: X(t) over X0 and time\")\n",
    "\n",
    "    # Save\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"X0_time_heatmap.png\")\n",
    "\n",
    "    plt.savefig(out_path, dpi=140, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4eb927b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BA1_X0_time_heatmap2.png'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0_values= np.linspace(0.2, 0.9, 10, dtype= float)\n",
    "time_points= np.linspace(1, 100, 100, dtype= int)\n",
    "BA1_X0_time_df = pd.DataFrame(BA1_X0_time_array, index=time_points, columns=X0_values)\n",
    "plot_X0_time_heatmap(df=BA1_X0_time_df, out_path = \"BA1_X0_time_heatmap2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f816eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_timeseries_trial(\n",
    "    T: int = 200,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    seed: Optional[int] = None,\n",
    "    policy: Optional[Callable] = None,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Run a single simulation and return X(t), I(t), and the model dataframe.\"\"\"\n",
    "\n",
    "    scenario = {\n",
    "        # Either provide `ratio` to pin the initial a_I/b, or explicit `a0`.\n",
    "        # Defaults here mirror the classroom-friendly values.\n",
    "        # If `ratio` is present, we compute `a0 = ratio*b - beta_I*I0`.\n",
    "        \"a0\": 2.0,\n",
    "        \"ratio\": None,\n",
    "        \"beta_I\": 3.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.1,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"random\",\n",
    "        \"n_nodes\": 100,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "        \"x0_frac\": 0.0,\n",
    "        \"collect\": True,\n",
    "        \"init_method\": \"random\",\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    # Compute a0 from ratio if provided to preserve initial payoff ratio\n",
    "    a0_for_model = scenario[\"a0\"]\n",
    "    if scenario.get(\"ratio\") is not None:\n",
    "        a0_for_model = float(scenario[\"ratio\"]) * float(scenario[\"b\"]) - float(scenario[\"beta_I\"]) * float(scenario[\"I0\"])\n",
    "\n",
    "    model = EVStagHuntModel(\n",
    "        a0=a0_for_model,\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        I0=scenario[\"I0\"],\n",
    "        seed=seed,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        collect=True,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    if scenario.get(\"X0_frac\", 0.0) > 0.0:\n",
    "        set_initial_adopters(\n",
    "            model,\n",
    "            scenario[\"X0_frac\"],\n",
    "            method=scenario.get(\"init_method\", \"random\"),\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "    for t in range(T):\n",
    "        if policy is not None:\n",
    "            policy(model, t)\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe().copy()\n",
    "    return df[\"X\"].to_numpy(), df[\"I\"].to_numpy(), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d28cf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = {\n",
    "    \"network_type\": \"ER\",  # \"ER\", \"BA\", \"WS\", \"grid\"\n",
    "    \"n_nodes\": 300,\n",
    "    \"p\": 0.1,  # only used for ER or WS\n",
    "    \"m\": 2, \n",
    "    \"k\": 30,    # only used for BA\n",
    "    \"beta_I\": 2.0,\n",
    "    \"b\": 2.0,\n",
    "    \"g_I\": 0.05,\n",
    "    \"I0\": 0.1,\n",
    "}\n",
    "\n",
    "X0_values = np.linspace(0.2, 0.9, 10)  # sweep from 20% to 90%\n",
    "n_trials = 50\n",
    "T = 200\n",
    "\n",
    "probabilities = []\n",
    "\n",
    "for X0 in X0_values:\n",
    "    scenario[\"X0_frac\"] = X0\n",
    "    final_X = []\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        seed = 42 + i\n",
    "        X, I, _ = run_timeseries_trial(T=T, scenario_kwargs=scenario, seed=seed)\n",
    "        final_X.append(X[-1])  # store final adoption\n",
    "\n",
    "    final_X = np.array(final_X)\n",
    "    prob = np.mean(final_X >= high_adoption_threshold)\n",
    "    probabilities.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca07318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of reaching high adoption: 0.0\n",
      "Mean final adoption: 0.0\n",
      "Std final adoption: 0.0\n"
     ]
    }
   ],
   "source": [
    "final_X = np.array(final_X)\n",
    "high_adoption_threshold = 0.8\n",
    "prob_high_adoption = np.mean(final_X >= high_adoption_threshold)\n",
    "\n",
    "print(\"Probability of reaching high adoption:\", prob_high_adoption)\n",
    "print(\"Mean final adoption:\", final_X.mean())\n",
    "print(\"Std final adoption:\", final_X.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
